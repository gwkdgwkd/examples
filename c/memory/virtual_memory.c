#include <stdio.h>

// 对于CPU来说，内存仅是一个存放指令和数据的地方，并不能在内存中完成计算，
// 必须将数据都读取到CPU内部才能进行加法运算。
// CPU是一个复杂的计算机部件，它内部又包含很多小零件：
// 1.运算单元是CPU的大脑，负责加减乘除、比较、位移等工作，每种运算都有对应的电路，速度很快。
// 2.寄存器（Register）是CPU内部非常小、非常快速的存储部件，它的容量很有限，
//   对于32位的CPU，每个寄存器一般能存储32位（4个字节）的数据，
//   对于64位的CPU，每个寄存器一般能存储64位（8个字节）的数据。
//   为了完成各种复杂的功能，现代CPU内置了几十甚至上百的寄存器，嵌入式系统寄存器数量较少。
//   经常听说多少位的CPU，指的就是寄存器的的位数。
//   现在个人电脑使用的CPU已经进入了64位时代，例如Intel的Core i3、i5、i7等。
//   寄存器在程序的执行过程中至关重要，不可或缺，它们可以用来完成数学运算、
//   控制循环次数、控制程序的执行流程、标记CPU运行状态等。
// 3.那么，在CPU内部为什么又要设置缓存呢？
//   虽然内存的读取速度已经很快了，但是和CPU比起来，还是有很大差距的，不是一个数量级的，
//   如果每次都从内存中读取数据，会严重拖慢CPU的运行速度，CPU经常处于等待状态，无事可做。
//   在CPU内部设置一个缓存，可以将使用频繁的数据暂时读取到缓存，需要同一地址上的数据时，
//   就不用大老远地再去访问内存，直接从缓存中读取即可。
//   在购买CPU时，也会经常关心缓存容量，例如Intel Core i7 3770K的三级缓存为8MB，
//   二级缓存为256KB，一级缓存为32KB，容量越大，CPU越强悍，缓存的容量是有限的，
//   CPU只能从缓存中读取到部分数据，对于使用不是很频繁的数据，会绕过缓存，直接到内存中读取。
//   所以不是每次都能从缓存中得到数据，这就是缓存的命中率，能够从缓存中读取就命中，否则就没命中。
//   关于缓存的命中率又是一门学问，哪些数据保留在缓存，哪些数据不保留，都有复杂的算法。

// CPU指令
// 要想让CPU工作，必须借助特定的指令，例如add用于加法运算，sub用于除法运算，
// cmp用于比较两个数的大小，这称为CPU的指令集（Instruction Set）。
// C语言代码最终也会编译成一条一条的CPU指令。
// 不同型号的CPU支持的指令集会有所差异，但绝大部分是相同的。
// 寄存器这个小而快速的存储部件，它在程序运行过程中起着至关重要的作用，
// CPU就是用它来记录程序的运行状态，然后根据它的值再决定下一步的操作。

// 虚拟地址
// 虚拟地址的整个想法是这样的：
// 把程序给出的地址看做是一种虚拟地址（Virtual Address），
// 然后通过某些映射的方法，将这个虚拟地址转换成实际的物理地址。
// 这样，只要能够妥善地控制这个虚拟地址到物理地址的映射过程，
// 就可以保证程序每次运行时都可以使用相同的地址。
// 用户程序在运行时不希望介入到这些复杂的内存管理过程中，作为普通的程序，
// 它需要的是一个简单的执行环境，有自己的内存，有自己的CPU，
// 好像整个程序占有整个计算机而不用关心其他的程序。
// 除了在编程时可以使用固定的内存地址，给程序员带来方便外，
// 使用虚拟地址还能够使不同程序的地址空间相互隔离，提高内存使用效率。
// 1.使不同程序的地址空间相互隔离
//   如果所有程序都直接使用物理内存，那么程序所使用的地址空间不是相互隔离的。
//   恶意程序可以很容易改写其他程序的内存数据，以达到破坏的目的；
//   有些非恶意、但是有Bug的程序也可能不小心修改其他程序数据，导致其崩溃。
//   这对于需要安全稳定的计算机环境的用户来说是不能容忍的，
//   用户希望他在使用计算机的时候，其中一个任务失败了，至少不会影响其他任务。
//   使用了虚拟地址后，程序A和程序B虽然都可以访问同一个地址，
//   但它们对应的物理地址是不同的，无论如何操作，都不会修改对方的内存。
// 2.提高内存使用效率
//   使用虚拟地址后，操作系统会更多地介入到内存管理工作中，这使得控制内存权限成为可能。
//   例如，我们希望保存数据的内存没有执行权限，保存代码的内存没有修改权限，
//   操作系统占用的内存普通程序没有读取权限等。
//   另外，当物理内存不足时，操作系统能够更加灵活地控制换入换出的粒度，
//   磁盘I/O是非常耗时的工作，这能够从很大程度上提高程序性能。

// 虚拟地址空间
// 所谓虚拟地址空间，就是程序可以使用的虚拟地址的有效范围。
// 虚拟地址和物理地址的映射关系由操作系统决定，相应地，
// 虚拟地址空间的大小也由操作系统决定，但还会受到编译模式的影响。

// CPU的数据处理能力
// CPU是计算机的核心，决定了计算机的数据处理能力和寻址能力，也即决定了计算机的性能。
// CPU一个时钟内处理的数据的大小由寄存器的位数和数据总线的宽度决定，通常所说的多少位的CPU，
// 除了可以理解为寄存器的位数，也可以理解数据总线的宽度，通常情况下它们是相等的。
// 数据总线和主频都是CPU的重要指标：
// 数据总线决定了CPU单次的数据处理能力，主频决定了CPU单位时间内的数据处理次数，
// 它们的乘积就是CPU单位时间内的数据处理量，数据总线和地址总线不是一回事，
// 数据总线用于在CPU和内存之间传输数据，地址总线用于在内存上定位数据，
// 它们之间没有必然的联系，宽度并不一定相等。
// 实际情况是，地址总线的宽度往往随着数据总线的宽度而增长，以访问更大的内存。

// 编译模式
// 为了兼容不同的平台，现代编译器大都提供两种编译模式：32位模式和64位模式。
// 在32位模式下，一个指针或地址占用4个字节的内存，共有32位，
// 理论上能够访问的虚拟内存空间大小为2^32=0X100000000Bytes，
// 即4GB，有效虚拟地址范围是0~0XFFFFFFFF。
// 在64位编译模式下，一个指针或地址占用8个字节的内存，共有64位，
// 理论上能够访问的虚拟内存空间大小为2^64。
// 这是一个很大的值，几乎是无限的，就目前的技术来讲，不但物理内存不可能达到这么大，
// CPU的寻址能力也没有这么大，实现64位长的虚拟地址只会增加系统的复杂度和地址转换的成本，
// 带不来任何好处，所以Windows和Linux都对虚拟地址进行了限制，
// 仅使用虚拟地址的低48位（6个字节），总的虚拟地址空间大小为2^48=256TB。
// 需要注意的是：
// 1.32位的操作系统只能运行32位的程序（以32位模式编译的程序），
//   64位操作系统可以同时运行32位的程序（为了向前兼容）和64位的程序；
// 2.64位的CPU运行64位的程序才能发挥它的最大性能，运行32位的程序会白白浪费一部分资源。
// 这里所说的32位环境是指：32位的CPU+32位的操作系统+32位的程序。
// 另外需要说明的是，32位环境拥有非常经典的设计，易于理解，适合教学，
// 现有的很多资料都是以32位环境为基础进行讲解的。

// 关于虚拟地址和物理地址的映射有很多思路，可以假设以程序为单位，
// 把一段与程序运行所需要的同等大小的虚拟空间映射到某段物理空间。
// 1.地址隔离：程序A和程序B分别被映射到了两块不同的物理内存，它们之间没有任何重叠，
//   如果程序A访问的虚拟地址超出了范围，系统就会判断这是一个非法的访问，
//   拒绝这个请求，并将这个错误报告给用户，通常的做法就是强制关闭程序。
// 2.程序可以使用固定的内存地址：虚拟内存无论被映射到物理内存的哪一个区域，
//   对于程序员来说都是透明的，不需要关心物理地址的变化，
//   只需要按照虚拟地址来编写程序、放置变量即可，程序不再需要重定位。
// 3.内存使用效率问题：以程序为单位对虚拟内存进行映射时，如果物理内存不足，
//   被换入换出到磁盘的是整个程序，这样势必会导致大量的磁盘读写操作，
//   严重影响运行速度，所以这种方法还是显得粗糙，粒度比较大。

// 内存分页机制
// 当一个程序运行时，在某个时间段内，它只是频繁地用到了一小部分数据，
// 也就是说，程序的很多数据其实在一个时间段内都不会被用到。
// 以整个程序为单位进行映射，不仅会将暂时用不到的数据从磁盘中读取到内存，
// 也会将过多的数据一次性写入磁盘，这会严重降低程序的运行效率。
// 现代计算机都使用分页的方式对虚拟地址空间和物理地址空间进行分割和映射，
// 以减小换入换出的粒度，提高程序运行效率。
// 分页（Paging）的思想是指把地址空间人为地分成大小相等（且固定）的若干份，
// 这样的一份称为一页，就像一本书由很多页面组成，每个页面的大小相等。
// 如此，就能够以页为单位对内存进行换入换出：
// 1.当程序运行时，只需要将必要的数据从磁盘读取到内存，
//   暂时用不到的数据先留在磁盘中，什么时候用到什么时候读取；
// 2.当物理内存不足时，只需要将原来程序的部分数据写入磁盘，
//   腾出足够的空间即可，不用把整个程序都写入磁盘。

// 关于页的大小
// 页的大小是固定的，由硬件决定，或硬件支持多种大小的页，由操作系统选择决定页的大小。
// 比如Intel Pentium系列处理器支持4KB或4MB的页大小，那么操作系统可以选择每页大小为4KB，
// 也可以选择每页大小为4MB，但是在同一时刻只能选择一种大小，所以对整个系统来说大小是固定的。
// 目前几乎所有PC上的操作系统都是用4KB大小的页。
// 假设我们使用的PC机是32位的，那么虚拟地址空间总共有4GB，
// 按照4KB每页分的话，总共有2^32/2^12=2^20=1M=1048576个页，物理内存也是同样的分法。
// 虚拟空间的页叫做虚拟页（VP，Virtual Page），
// 把物理内存中的页叫做物理页（PP，Physical Page），
// 把磁盘中的页叫做磁盘页（DP，Disk Page）。

// 内存地址的转换是通过一种叫做页表（Page Table）的机制来完成的：
// 1.直接使用数组转换
//   最容易想到的映射方案是使用数组：每个数组元素保存一个物理地址，
//   而把虚拟地址作为数组下标，这样就能够很容易地完成映射，并且效率不低。
//   但是这样的数组有2^32个元素，每个元素大小为4个字节，总共占用16GB的内存，显现是不现实的！
// 2.使用一级页表
//   既然内存是分页的，只要我们能够定位到数据所在的页，
//   以及它在页内的偏移（也就是距离页开头的字节数），就能够转换为物理地址。
//   虚拟地址空间大小为4GB，总共包含2^32/2^12=2^20=1K*1K=1M=1048576个页面，
//   可以定义一个这样的数组：它包含2^20=1M个元素，
//   每个元素的值为页面编号（也就是位于第几个页面），长度为4字节，整个数组共占用4MB的内存空间。
//   这样的数组就称为页表（Page Table），它记录了地址空间中所有页的编号。
//   虚拟地址长度为32位，不妨进行一下切割，将高20位作为页表数组的下标，低12位作为页内偏移。
//   因为页表数组共有2^20=1M个元素，使用虚拟地址的高20位作为下标，正好能够访问数组中的所有元素；
//   并且，一个页面的大小为2^12=4KB，使用虚拟地址的低12位恰好能够表示所有偏移。
//   这种方案，不管程序占用多大的内存，都要为页表数组分配4M的内存空间（页表数组必须放在物理内存中），
//   因为虚拟地址空间中的高1G或2G是被系统占用的，必须保证较大的数组下标有效。
//   现在硬件很便宜了，内存容量大了，很多电脑都配备4G或8G的内存，
//   页表数组占用4M内存或许不觉得多，但在32位系统刚刚发布的时候，
//   内存还是很紧缺的资源，很多电脑才配备100M甚至几十兆的内存，
//   4M内存就显得有点大了，所以还得对上面的方案进行改进，压缩页表数组所占用的内存。
// 2.使用两级页表
//   上面的页表共有2^20=2^10*2^10个元素，为了压缩页表的存储空间，
//   可以将上面的页表分拆成2^10=1K=1024个小的页表，这样每个页表只包含2^10=1K=1024个元素，
//   占用2^10*4=4KB的内存，也即一个页面的大小。
//   这1024个小的页表，可以存储在不同的物理页，它们之间可以是不连续的。
//   采用这样的两级页表的一个明显优点是，如果程序占用的内存较少，
//   分散的小页表的个数就会远远少于1024个，只会占用很少的一部分存储空间（远远小于4M）。
//   在极少数的情况下，程序占用的内存非常大，布满了4G的虚拟地址空间，
//   这样小页表的数量可能接近甚至等于1024，再加上页目录占用的存储空间，
//   总共是4MB+4KB，比上面使用一级页表的方案仅仅多出4KB的内存。
//   这是可以容忍的，因为很少出现如此极端的情况。
//   也就是说，使用两级页表后，页表占用的内存空间不固定，
//   它和程序本身占用的内存空间成正比，从整体上来看，会比使用一级页表占用的内存少得多。
// 3.使用多级页表
//   对于64位环境，虚拟地址空间达到256TB，使用二级页表占用的存储空间依然不小，所以会更加细化，
//   从而使用三级页表甚至多级页表，这样就会有多个页目录，虚拟地址也会被分割成多个部分。

// MMU
// 通过页表完成虚拟地址和物理地址的映射时，要经过多次转换，还要进行计算，
// 如果由操作系统来完成这项工作，那将会成倍降低程序的性能，得不偿失，所以这种方式是不现实的。
// 在CPU内部，MMU（Memory Management Unit，内存管理单元）负责将虚拟地址映射为物理地址。
// 在页映射模式下，CPU发出的是虚拟地址，也就是我们在程序中看到的地址，
// 这个地址会先交给MMU，经过MMU转换以后才能变成了物理地址。
// 即便是这样，MMU也要访问好几次内存，性能依然堪忧，
// 所以在MMU内部又增加了一个缓存，专门用来存储页目录和页表。
// MMU内部的缓存有限，当页表过大时，也只能将部分常用页表加载到缓存，
// 但这已经足够了，因为经过算法的巧妙设计，可以将缓存的命中率提高到90%，
// 剩下的10%的情况无法命中，再去物理内存中加载页表。
// 有了硬件的直接支持，使用虚拟地址和使用物理地址相比，损失的性能已经很小，在可接受的范围内。
// MMU只是通过页表来完成虚拟地址到物理地址的映射，但不会构建页表，构建页表是操作系统的任务。
// 在程序加载到内存以及程序运行过程中，操作系统会不断更新程序对应的页表，
// 并将页目录的物理地址保存到CR3寄存器。
// MMU向缓存中加载页表时，会根据CR3寄存器找到页目录，
// 再找到页表，最终通过软件和硬件的结合来完成内存映射。
// CR3是CPU内部的一个寄存器，专门用来保存页目录的物理地址。
// 操作系统在构建页表时将内存权限定义好，当MMU对虚拟地址进行映射时，首先检查低12位，
// 看当前程序是否有权限使用，如果有，就完成映射，如果没有，就产生一个异常，并交给操作系统处理。
// 操作系统在处理这种内存错误时一般比较粗暴，会直接终止程序的执行。

int main() {
  // 这段代码不会产生编译和链接错误，但在运行程序时，为了输出字符串，
  // printf()需要访问虚拟地址为0XFFFF00000的内存，
  // 但是该虚拟地址是被操作系统占用的，程序没有权限访问，会被强制关闭。

  // 使用数值表示一个明确的地址：
  char *str = (char *)0XFFF00000;
  printf("%s\n", str);

  return 0;
}